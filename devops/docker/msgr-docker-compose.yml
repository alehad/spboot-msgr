version: '3'
services:
  msgr:
    container_name: docker-msgr
    image: alehad/msgr:2.2
    ports:
     - "80:8088"
     - "8080:8088"
    depends_on:
      redis:
          condition: service_healthy
      kibana:
          condition: service_healthy

  mongodb:
    container_name: docker-mongo
    image: mongo
    ports:
     - "27017:27017"
    volumes:
     - mongo-data:/data/db

  # mongo express is not required for running msgr but useful to inspect data stored in mongo
  # alternative to specifying mongo-express services as part of compose.yaml is to start it via
  # docker cli, but note that in that case you need to *link it* to network in which mongo and 
  # msgr app are running. see my gitdocs/docker notes for more details on this
  mongo-express:
    container_name: docker-mongo-express
    image: mongo-express
    environment:
      - ME_CONFIG_MONGODB_SERVER=mongodb
      - ME_CONFIG_MONGODB_PORT=27017
    depends_on:
     - mongodb
    ports:
     - "8082:8081"

  zookeeper:
    container_name: docker-zookeeper
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181
  
  kafka-broker:
    container_name: docker-kafka
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:9092,CONNECTIONS_FROM_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONNECTIONS_FROM_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Elasticsearch Docker Images: https://www.docker.elastic.co/
  elasticsearch-es-http:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.2
    container_name: docker-elasticsearch
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300

  kibana:
    container_name: docker-kibana
    image: docker.elastic.co/kibana/kibana:7.6.2
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch-es-http:9200
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch-es-http
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

  # made redis depend on kafka, just to ensure orderly initialization of images, no actual dependancy
  redis:
    image: docker.io/bitnami/redis:7.0
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
      - REDIS_DISABLE_COMMANDS=FLUSHDB,FLUSHALL
    ports:
      - '6379:6379'
    volumes:
      - 'redis_data:/bitnami/redis/data'
    depends_on:
     - kafka-broker
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 2s
      retries: 10

volumes:
  elasticsearch-data:
    driver: local
  mongo-data:
    driver: local
  redis_data:
    driver: local